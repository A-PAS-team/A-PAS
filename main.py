import cv2
import torch
import torch.nn as nn
import numpy as np
from ultralytics import YOLO
from collections import deque

# ==========================================
# âš™ï¸ [ì„¤ì •] í•™ìŠµ í™˜ê²½ê³¼ 100% ì¼ì¹˜ í•„ìˆ˜
# ==========================================
IMG_W, IMG_H = 1920, 1080 
SEQ_LENGTH = 5     
PRED_LENGTH = 3    
HIDDEN_SIZE = 128
NUM_LAYERS = 2

YOLO_MODEL_PATH = "yolov8n.pt"
LSTM_MODEL_PATH = "models/best_trajectory_model.pth"
VIDEO_PATH = "test_video.mp4" 

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ==========================================
# ğŸ§  [ëª¨ë¸ ì •ì˜]
# ==========================================
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers):
        super(LSTMModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, PRED_LENGTH * 2)

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out.view(-1, PRED_LENGTH, 2)

# ëª¨ë¸ ë¡œë“œ
yolo_model = YOLO(YOLO_MODEL_PATH)
lstm_model = LSTMModel(2, HIDDEN_SIZE, NUM_LAYERS).to(device)
lstm_model.load_state_dict(torch.load(LSTM_MODEL_PATH, map_location=device))
lstm_model.eval()

track_history = {}
future_predictions = {} # ì¶©ëŒ íŒì •ì„ ìœ„í•´ ëª¨ë“  ê°ì²´ì˜ ë¯¸ë˜ ìœ„ì¹˜ ì €ì¥
cap = cv2.VideoCapture(VIDEO_PATH)

while cap.isOpened():
    success, frame = cap.read()
    if not success: break
    frame = cv2.resize(frame, (IMG_W, IMG_H))
    
    results = yolo_model.track(frame, persist=True, verbose=False)
    collision_detected = False
    future_predictions.clear()

    if results[0].boxes.id is not None:
        boxes = results[0].boxes.xywh.cpu().numpy()
        track_ids = results[0].boxes.id.int().cpu().tolist()
        
        # 1ë‹¨ê³„: ëª¨ë“  ê°ì²´ì˜ ë¯¸ë˜ ê²½ë¡œ ì˜ˆì¸¡
        for box, track_id in zip(boxes, track_ids):
            x, y, w, h = box
            if track_id not in track_history:
                track_history[track_id] = deque(maxlen=SEQ_LENGTH)
            track_history[track_id].append((float(x), float(y)))

            if len(track_history[track_id]) == SEQ_LENGTH:
                input_seq = np.array(list(track_history[track_id]))
                input_seq[:, 0] /= IMG_W
                input_seq[:, 1] /= IMG_H
                input_seq_torch = torch.FloatTensor([input_seq]).to(device)
                
                with torch.no_grad():
                    pred = lstm_model(input_seq_torch).cpu().numpy()[0]
                    # ë‹¤ì‹œ í”½ì…€ ì¢Œí‘œë¡œ ë³µì›í•´ì„œ ì €ì¥
                    pred[:, 0] *= IMG_W
                    pred[:, 1] *= IMG_H
                    future_predictions[track_id] = pred

        # 2ë‹¨ê³„: ì¶©ëŒ ê°ì§€ ë° ì‹œê°í™”
        for track_id, pred in future_predictions.items():
            # ê³¼ê±° ê¶¤ì  ê·¸ë¦¬ê¸° (íŒŒë€ìƒ‰)
            pts = np.array(list(track_history[track_id]), dtype=np.int32).reshape((-1, 1, 2))
            cv2.polylines(frame, [pts], False, (255, 0, 0), 2)

            # ë¯¸ë˜ ì˜ˆì¸¡ ì  ê·¸ë¦¬ê¸° (ë¹¨ê°„ìƒ‰)
            for p_x, p_y in pred:
                cv2.circle(frame, (int(p_x), int(p_y)), 5, (0, 0, 255), -1)

            # ì¶©ëŒ ì²´í¬: ë‹¤ë¥¸ ê°ì²´ë“¤ì˜ ë¯¸ë˜ ìœ„ì¹˜ì™€ ë¹„êµ
            for other_id, other_pred in future_predictions.items():
                if track_id == other_id: continue
                
                # ë‚´ ë§ˆì§€ë§‰ ì˜ˆì¸¡ ì§€ì ê³¼ ìƒëŒ€ë°©ì˜ ë§ˆì§€ë§‰ ì˜ˆì¸¡ ì§€ì  ì‚¬ì´ ê±°ë¦¬ ê³„ì‚°
                dist = np.linalg.norm(pred[-1] - other_pred[-1])
                
                if dist < 80: # ì¶©ëŒ ì„ê³„ê°’ (80í”½ì…€ ì´ë‚´ë©´ ìœ„í—˜)
                    collision_detected = True
                    # ìœ„í—˜ ê°ì²´ë“¤ ê°•ì¡° (ë…¸ë€ìƒ‰ ë°•ìŠ¤)
                    cv2.putText(frame, "COLLISION RISK", (int(pred[-1,0]), int(pred[-1,1])-20),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)

    # 3ë‹¨ê³„: ì „ì²´ í™”ë©´ ê²½ê³  ë ˆì´ì•„ì›ƒ
    if collision_detected:
        # í™”ë©´ í…Œë‘ë¦¬ì— ë¹¨ê°„ìƒ‰ ì‚¬ê°í˜•
        cv2.rectangle(frame, (0, 0), (IMG_W, IMG_H), (0, 0, 255), 30)
        cv2.putText(frame, "!!! EMERGENCY WARNING !!!", (IMG_W//2 - 400, 100), 
                    cv2.FONT_HERSHEY_DUPLEX, 2, (0, 0, 255), 5)

    cv2.imshow("A-PAS Final: Collision Prevention", frame)
    if cv2.waitKey(1) & 0xFF == ord("q"): break

cap.release()
cv2.destroyAllWindows()