import cv2
import torch
import torch.nn as nn
import numpy as np
from ultralytics import YOLO
from collections import deque

# ==========================================
# âš™ï¸ [ì„¤ì •] í•™ìŠµ(tr_trajectory.py)ê³¼ ë°˜ë“œì‹œ ì¼ì¹˜í•´ì•¼ í•¨
# ==========================================
IMG_W, IMG_H = 1920, 1080 
SEQ_LENGTH = 10     # 5ì—ì„œ 10ìœ¼ë¡œ ìˆ˜ì • (10-10 ë²•ì¹™ ì ìš©)
PRED_LENGTH = 10    # 3ì—ì„œ 10ìœ¼ë¡œ ìˆ˜ì • (1ì´ˆ ë’¤ ì˜ˆì¸¡)
HIDDEN_SIZE = 128
NUM_LAYERS = 2

YOLO_MODEL_PATH = "yolov8n.pt"
LSTM_MODEL_PATH = "models/best_trajectory_model.pth"
VIDEO_PATH = "my_video.mp4" 

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ==========================================
# ğŸ§  [ëª¨ë¸ ì •ì˜]
# ==========================================
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers):
        super(LSTMModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, PRED_LENGTH * 2)

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out.view(-1, PRED_LENGTH, 2)

# ëª¨ë¸ ë¡œë“œ
yolo_model = YOLO(YOLO_MODEL_PATH)
lstm_model = LSTMModel(2, HIDDEN_SIZE, NUM_LAYERS).to(device)
lstm_model.load_state_dict(torch.load(LSTM_MODEL_PATH, map_location=device))
lstm_model.eval()

track_history = {}
last_predictions = {} # ì´ìƒ í–‰ë™(Loss) ê³„ì‚°ì„ ìœ„í•œ ì €ì¥ì†Œ
cap = cv2.VideoCapture(VIDEO_PATH)

# ==========================================
# ğŸ¬ [ì‹¤í–‰] ë©”ì¸ ë£¨í”„
# ==========================================
while cap.isOpened():
    success, frame = cap.read()
    if not success: break
    frame = cv2.resize(frame, (IMG_W, IMG_H))
    
    results = yolo_model.track(frame, persist=True, verbose=False)
    collision_risk = False
    all_current_preds = {} # ì´ë²ˆ í”„ë ˆì„ì˜ ëª¨ë“  ë¯¸ë˜ ì¢Œí‘œ ì €ì¥

    if results[0].boxes.id is not None:
        boxes = results[0].boxes.xywh.cpu().numpy()
        track_ids = results[0].boxes.id.int().cpu().tolist()
        
        for box, track_id in zip(boxes, track_ids):
            x, y, w, h = box
            curr_pos = np.array([float(x), float(y)])
            
            # 1. ì´ìƒ í–‰ë™(Anomaly Loss) ê³„ì‚°
            if track_id in last_predictions:
                # ì´ì „ í”„ë ˆì„ì—ì„œ ì˜ˆì¸¡í–ˆë˜ 'í˜„ì¬ ì‹œì 'ì˜ ìœ„ì¹˜ì™€ ì‹¤ì œ ìœ„ì¹˜ ë¹„êµ
                pred_pos = last_predictions[track_id]
                anomaly_loss = np.linalg.norm(curr_pos - pred_pos)
                
                # ì˜¤ì°¨ê°€ í¬ë©´ (ì˜ˆ: 50px ì´ìƒ) ê²½ê³  í…ìŠ¤íŠ¸ í‘œì‹œ
                if anomaly_loss > 50:
                    cv2.putText(frame, f"UNSTABLE: {int(anomaly_loss)}", (int(x), int(y)-40),
                                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 165, 255), 2)

            if track_id not in track_history:
                track_history[track_id] = deque(maxlen=SEQ_LENGTH)
            track_history[track_id].append(curr_pos)

            # 2. ë¯¸ë˜ ê²½ë¡œ ì˜ˆì¸¡
            if len(track_history[track_id]) == SEQ_LENGTH:
                input_seq = np.array(list(track_history[track_id]))
                input_seq[:, 0] /= IMG_W
                input_seq[:, 1] /= IMG_H
                input_seq_torch = torch.FloatTensor([input_seq]).to(device)
                
                with torch.no_grad():
                    pred = lstm_model(input_seq_torch).cpu().numpy()[0]
                    pred[:, 0] *= IMG_W
                    pred[:, 1] *= IMG_H
                    all_current_preds[track_id] = pred
                    # ë‹¤ìŒ í”„ë ˆì„ ì˜¤ì°¨ ê³„ì‚°ì„ ìœ„í•´ ì²« ë²ˆì§¸ ì˜ˆì¸¡ ì§€ì  ì €ì¥
                    last_predictions[track_id] = pred[0] 

                    # ì˜ˆì¸¡ ê²½ë¡œ ì‹œê°í™” (ë¹¨ê°„ ì„ )
                    cv2.polylines(frame, [pred.astype(np.int32)], False, (0, 0, 255), 2)

        # 3. ì¶©ëŒ ê°ì§€ ë¡œì§ (ê°ì²´ ê°„ ê±°ë¦¬ ë¹„êµ)
        for id1, pred1 in all_current_preds.items():
            for id2, pred2 in all_current_preds.items():
                if id1 >= id2: continue # ì¤‘ë³µ ê²€ì‚¬ ë°©ì§€
                
                # ë¯¸ë˜ 1ì´ˆ ë’¤(ë§ˆì§€ë§‰ ì )ì˜ ê±°ë¦¬ ê³„ì‚°
                dist = np.linalg.norm(pred1[-1] - pred2[-1])
                if dist < 100: # 100í”½ì…€ ì´ë‚´ ì ‘ê·¼ ì‹œ ìœ„í—˜
                    collision_risk = True
                    cv2.line(frame, tuple(pred1[-1].astype(int)), tuple(pred2[-1].astype(int)), (0, 255, 255), 3)

    # 4. ì „ì²´ ì‹œìŠ¤í…œ ê²½ê³  ì¶œë ¥
    if collision_risk:
        cv2.rectangle(frame, (0, 0), (IMG_W, IMG_H), (0, 0, 255), 20)
        cv2.putText(frame, "!!! COLLISION WARNING !!!", (IMG_W//2-350, 80), 
                    cv2.FONT_HERSHEY_DUPLEX, 2, (0, 0, 255), 4)

    cv2.imshow("A-PAS Final Monitoring", frame)
    if cv2.waitKey(1) & 0xFF == ord("q"): break

cap.release()
cv2.destroyAllWindows()