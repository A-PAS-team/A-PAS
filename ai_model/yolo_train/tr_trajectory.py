import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import pandas as pd
import numpy as np
import glob
import os

# ==========================================
# âš™ï¸ [ì„¤ì •] í•˜ì´í¼íŒŒë¼ë¯¸í„° ë° ê²½ë¡œ
# ==========================================
TRAIN_DATA_DIR = "data/Training"
VAL_DATA_DIR = "data/Validation"
MODEL_SAVE_DIR = "models"
os.makedirs(MODEL_SAVE_DIR, exist_ok=True)

# í•„ìˆ˜ ì„¤ì • (ë³¸ì¸ ì˜ìƒ í•´ìƒë„ì— ë§ê²Œ ìˆ˜ì •)
IMG_W, IMG_H = 1920, 1080 
SEQ_LENGTH = 10     
PRED_LENGTH = 10    
INPUT_SIZE = 2      
HIDDEN_SIZE = 128   
NUM_LAYERS = 2      
BATCH_SIZE = 64
EPOCHS = 50
LEARNING_RATE = 0.001

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ==========================================
# ğŸ“Š [ë°ì´í„°ì…‹] ì •ê·œí™” ë¡œì§ í¬í•¨
# ==========================================
class TrajectoryDataset(Dataset):
    def __init__(self, data_dir):
        self.sequences = []
        self.labels = []
        
        csv_files = glob.glob(os.path.join(data_dir, "*.csv"))
        for file in csv_files:
            df = pd.read_csv(file)
            for track_id, group in df.groupby('track_id'):
                # ì¢Œí‘œë¥¼ 0~1 ì‚¬ì´ë¡œ ì •ê·œí™”
                coords = group[['x_center', 'y_center']].values
                coords[:, 0] /= IMG_W
                coords[:, 1] /= IMG_H
                
                if len(coords) < (SEQ_LENGTH + PRED_LENGTH):
                    continue
                
                for i in range(len(coords) - SEQ_LENGTH - PRED_LENGTH + 1):
                    self.sequences.append(coords[i : i + SEQ_LENGTH])
                    self.labels.append(coords[i + SEQ_LENGTH : i + SEQ_LENGTH + PRED_LENGTH])

        self.sequences = torch.FloatTensor(np.array(self.sequences))
        self.labels = torch.FloatTensor(np.array(self.labels))

    def __len__(self): return len(self.sequences)
    def __getitem__(self, idx): return self.sequences[idx], self.labels[idx]

# ==========================================
# ğŸ§  [ëª¨ë¸] LSTM êµ¬ì¡° (batch_first ìˆ˜ì • ì™„ë£Œ)
# ==========================================
class LSTMModel(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers):
        super(LSTMModel, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, PRED_LENGTH * 2)

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :]) 
        return out.view(-1, PRED_LENGTH, 2)

# í•™ìŠµ ì‹¤í–‰ ë¡œì§ (ì´ì „ê³¼ ë™ì¼í•˜ì§€ë§Œ ì •ê·œí™”ëœ ë°ì´í„°ë¡œ ìˆ˜í–‰)
# ... (ìƒëµ: ì´ì „ tr_trajectory.pyì˜ í•™ìŠµ ë£¨í”„ ë¶€ë¶„ê³¼ ë™ì¼)
# ==========================================
# ğŸš€ [ì‹¤í–‰] í•™ìŠµ ë£¨í”„
# ==========================================
# 1. ë°ì´í„° ë¡œë” ì¤€ë¹„
train_dataset = TrajectoryDataset(TRAIN_DATA_DIR)
val_dataset = TrajectoryDataset(VAL_DATA_DIR)

train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)

# 2. ëª¨ë¸, ì†ì‹¤í•¨ìˆ˜, ìµœì í™”ê¸° ì„¤ì •
model = LSTMModel(INPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS).to(device)
criterion = nn.MSELoss() # í‰ê·  ì œê³± ì˜¤ì°¨ (ì¢Œí‘œ ì˜¤ì°¨ ê³„ì‚°)
optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)

# 3. Epoch ë°˜ë³µ
best_val_loss = float('inf')

for epoch in range(EPOCHS):
    model.train()
    train_loss = 0
    for seqs, targets in train_loader:
        seqs, targets = seqs.to(device), targets.to(device)
        
        optimizer.zero_grad()
        outputs = model(seqs)
        loss = criterion(outputs, targets)
        loss.backward()
        optimizer.step()
        
        train_loss += loss.item()
    
    # ê²€ì¦(Validation)
    model.eval()
    val_loss = 0
    with torch.no_grad():
        for v_seqs, v_targets in val_loader:
            v_seqs, v_targets = v_seqs.to(device), v_targets.to(device)
            v_outputs = model(v_seqs)
            v_loss = criterion(v_outputs, v_targets)
            val_loss += v_loss.item()
    
    avg_train_loss = train_loss / len(train_loader)
    avg_val_loss = val_loss / len(val_loader)
    
    print(f"Epoch [{epoch+1}/{EPOCHS}] Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}")
    
    # ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì€ ëª¨ë¸ ì €ì¥
    if avg_val_loss < best_val_loss:
        best_val_loss = avg_val_loss
        torch.save(model.state_dict(), os.path.join(MODEL_SAVE_DIR, "best_trajectory_model.pth"))
        print(f"â­ ëª¨ë¸ ì €ì¥ ì™„ë£Œ! (Val Loss: {best_val_loss:.4f})")

print("\nğŸ‰ ëª¨ë“  í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")